# -*- coding: utf-8 -*-
"""suc_llamafile_GGUF_llamafilemodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lj5KrdimGfiLJM8btxWUIsKKqiyvkTkI
"""

!wget https://github.com/Mozilla-Ocho/llamafile/releases/download/0.9.2/llamafile-0.9.2

!pip install llamafile-0.9.2



!chmod +x /content/llamafile-0.9.2

!./content/llamafile-0.9.2

!chmod +x /content/llamafile-0.9.2
!./content/llamafile-0.9.2 --help

!wget https://github.com/Mozilla-Ocho/llamafile/releases/download/0.9.2/llamafile-0.9.2

!chmod +x /content/llamafile-0.9.2

!chmod +x /content/llamafile-0.9.2

!./llamafile-0.9.2 --help

!./llamafile-0.9.2 --

!wget https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-IQ3_M.gguf

"""### aشغال"""

!./llamafile-0.9.2  -m /content/Llama-3.2-1B-Instruct-IQ3_M.gguf -p hi

!wget https://huggingface.co/Mozilla/gemma-3-1b-it-llamafile/resolve/main/google_gemma-3-1b-it-Q4_K_M.llamafile

!./google_gemma-3-1b-it-Q4_K_M.llamafile -h

!./llamafile-0.9.2 -m /content/google_gemma-3-1b-it-Q4_K_M.llamafile -p hi

!./llamafile-0.9.2.1 -h

!chmod +x llamafile-0.9.2.1

!./llamafile-0.9.2.1 -h

